<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Machine Learning Notes | mushetty.me</title>
<meta name="keywords" content="">
<meta name="description" content="Compilation of notes for Machine Learning class for Spring 2023.
 Administrative Stuff Topic 1  Workflow of Classification Problems (Supervised Learning) Statistical Approach  Classifier   Maximum Likelihood Estimation  Example   Convergence Naive Bayes Classifier How do you quantify the quality of a classifier?   Topic 2  Nearest K-Neighbor  Importance of Closeness for k-Nearest Neighbors  Distances Similarities       Topic 3 Topic 4 Topic 5 Topic 6 Topic 7 Topic 8 Topic 9  Administrative Stuff  All homework is submitted via Gradescope.">
<meta name="author" content="">
<link rel="canonical" href="https://mushetty.me/notes/machinelearning/machine/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.a5456a2fb6485e28d3190c101c9f7fea21d7eddeb7cf1b8dddf20aeb314df0cf.css" integrity="sha256-pUVqL7ZIXijTGQwQHJ9/6iHX7d63zxuN3fIK6zFN8M8=" rel="preload stylesheet" as="style">
<link rel="stylesheet" href="" />
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://mushetty.me/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://mushetty.me/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://mushetty.me/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://mushetty.me/apple-touch-icon.png">
<link rel="mask-icon" href="https://mushetty.me/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            delimiters: [
                {left: "$$", right: "$$", display: true},
                {left: "$", right: "$", display: false}
            ]
        });
    });
</script>


<meta property="og:title" content="Machine Learning Notes" />
<meta property="og:description" content="Compilation of notes for Machine Learning class for Spring 2023.
 Administrative Stuff Topic 1  Workflow of Classification Problems (Supervised Learning) Statistical Approach  Classifier   Maximum Likelihood Estimation  Example   Convergence Naive Bayes Classifier How do you quantify the quality of a classifier?   Topic 2  Nearest K-Neighbor  Importance of Closeness for k-Nearest Neighbors  Distances Similarities       Topic 3 Topic 4 Topic 5 Topic 6 Topic 7 Topic 8 Topic 9  Administrative Stuff  All homework is submitted via Gradescope." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://mushetty.me/notes/machinelearning/machine/" /><meta property="article:section" content="notes" />
<meta property="article:published_time" content="2023-01-17T22:19:16-05:00" />
<meta property="article:modified_time" content="2023-02-01T20:49:38-05:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Machine Learning Notes"/>
<meta name="twitter:description" content="Compilation of notes for Machine Learning class for Spring 2023.
 Administrative Stuff Topic 1  Workflow of Classification Problems (Supervised Learning) Statistical Approach  Classifier   Maximum Likelihood Estimation  Example   Convergence Naive Bayes Classifier How do you quantify the quality of a classifier?   Topic 2  Nearest K-Neighbor  Importance of Closeness for k-Nearest Neighbors  Distances Similarities       Topic 3 Topic 4 Topic 5 Topic 6 Topic 7 Topic 8 Topic 9  Administrative Stuff  All homework is submitted via Gradescope."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "Machine Learning Notes",
      "item": "https://mushetty.me/notes/machinelearning/machine/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Machine Learning Notes",
  "name": "Machine Learning Notes",
  "description": "Compilation of notes for Machine Learning class for Spring 2023.\n Administrative Stuff Topic 1  Workflow of Classification Problems (Supervised Learning) Statistical Approach  Classifier   Maximum Likelihood Estimation  Example   Convergence Naive Bayes Classifier How do you quantify the quality of a classifier?   Topic 2  Nearest K-Neighbor  Importance of Closeness for k-Nearest Neighbors  Distances Similarities       Topic 3 Topic 4 Topic 5 Topic 6 Topic 7 Topic 8 Topic 9  Administrative Stuff  All homework is submitted via Gradescope.",
  "keywords": [
    
  ],
  "articleBody": "Compilation of notes for Machine Learning class for Spring 2023.\n Administrative Stuff Topic 1  Workflow of Classification Problems (Supervised Learning) Statistical Approach  Classifier   Maximum Likelihood Estimation  Example   Convergence Naive Bayes Classifier How do you quantify the quality of a classifier?   Topic 2  Nearest K-Neighbor  Importance of Closeness for k-Nearest Neighbors  Distances Similarities       Topic 3 Topic 4 Topic 5 Topic 6 Topic 7 Topic 8 Topic 9  Administrative Stuff  All homework is submitted via Gradescope.  Written parts must be PDFs and be typeset.  Plots and data analysis from programming part must be included in written part   Programming parts are mostly turned in as a separate assignment on Gradescope   40 % HW, 30% Midterm, 30% Final  Topic 1  Inputs encoded as vectors ($x \\in X$):  $\\vec{x} = $ Can think of each component as a measurement that you make   Output is another vector ($y \\in Y$):  $\\vec{y} = $   Goal is to figure out the function that maps x to y  You only have a limited number of samples from X  You need to make predictions from this limited sample size      Workflow of Classification Problems (Supervised Learning)  $(\\vec{x_{1}},y_{1}),(\\vec{x_{2}},y_{2})… \\in X \\times Y$  Example: $X = \\mathbb{R^{d}}$ and $Y = {0,1}$ for a binary classification from a image with d pixels Assumption: there exists a “relatively simple” function $f^{*}: X \\rightarrow Y$ such that $f^{*}(\\vec{x_{i}}) = y_{i}$ for most i  $*$ in ML implies some optimum value (in this case, an optimal function) Most includes that possibility that there is some fundamental noise in your data Say someone wrote a number that kind of looks like 7 and kinda looks like 1. For the same image, the true $y_{i}$ could be either 7 or 1 (depending on the person’s intentions). Hence, to force $f^{*}$ be a correct for all inputs misses this uncertainty in the true output   Learning task: given $n$ examples from the data, from $\\hat{f} \\approx f^{*}$  $\\hat{f}$ denotes a function that tries its best to be optimal   Goal: $\\hat{f}$ gives mostly correct prediction on unseen examples    Statistical Approach  $(\\vec{x_{1}},y_{1}),(\\vec{x_{2}},y_{2})…(\\vec{x_{n}},y_{n})$ samples are drawn from the underlying distribution  For simplicity, we assume each sample is drawn independently from the same underlying distribution is (called i.i.d. assumption)   The learning algorithm draws $\\hat{f}$ from a pool of models $\\mathbb{F}$ that maximizes the label agreement with the training data  How do we select $f \\in \\mathbb{F}$? Maximum likelihood (best fits the data) Maximum a posteriori (best fits the data but incorporates prior assumptions) Optimization of ‘loss’ criterion (best discriminates the labels)    Classifier  We are given a joint input/output space ($X \\times Y$)  The data is distributed like $D(X \\times Y)$  You have a region where your inputs can reside in ($X \\times Y$) and D tells you the density of inputs on the space You can visualize this space by either:  Taking slices at a fixed variable value ($P[Y,X=x]$) or the conditional distribution Adding up all the slices along a variable ($P[Y]$) or the marginal distribution       A classifier is a measurable function of the type $f: x \\in Y$  Ex1 (Constant): $f_{1}(\\vec{x}) = y$ for some fixed $y \\in Y$. Ex2(Threshold): $f_{2}(x) = \\begin{cases} 0\\ if \\ x \\geq 5 \\\\ 1 \\ otherwise \\end{cases}$ Ex3 (Majority class): $f_{3}(x) = arg\\ max_{y\\in Y} P[Y=y]$  This asks: What argument in Y yields the maximum probability? Implicitly, this probability is the marginalized distribution on X More explicitly, you can write probability as: $P[Y=y] = P_{y \\approx D}|_{Y}[Y=y]$  In words, you draw a (x,y) pair from D, and you only pay attention to the y part     None of these are particularly good/generally applicable classifiers Ex4 (Sample Average Class):  $\\frac{1}{n}\\Sigma \\mathbb{I}[f(x_{i}) = y_{i}]$  $\\mathbb{I}$ is the indicator function that maps a boolean expression (like $f(x_{i}) = y_{i}$) to either 0 (false) or 1 (true) This is from a sample     Ex5 (Population Average):  $\\mathbb{E}_{(x,y)\\in D}[\\mathbb{I}[f(x)=y]]= P[f(x)=y]$  This is on the entire population. Essentially a probability that states how often this classifier f gets the output correct called the accuracy function acc(f)       Let’s look at the following classifier:  $f(\\vec{x})= arg\\ max_{y\\in Y}\\ P[y=Y|X=\\vec{x}]$  In words, find y that maximizes the probability given a particular x (called Bayes classifier) This is the best classifier. But most of the time, you can’t actually compute $P[y=Y|X=\\vec{x}]$ for all inputs. You try your best to estimate these probabilities Proof:  Assume binary classification for output space (for simplicity)  Let $f(\\vec{x})= arg\\ max_{y\\in Y}\\ P[y=Y|X=\\vec{x}]$. Let $g(\\vec{x})\\rightarrow \\{0,1\\}$. Then $P_{(\\vec{x},y)}[g(\\vec{x})=y] \\leq P_{(\\vec{x},y)}[f(\\vec{x})=y]$   Let’s look at a single example (Fix $\\vec{x}\\in X$). Then for any classifier h  $P[h(\\vec{x})=y|X=\\vec{x}]=P[h(\\vec{x})=1|X=\\vec{x}]+P[h(\\vec{x})=0|X=\\vec{x}]$ Since $h(\\vec{x})=1$ is a constant, we can use $\\mathbb{I}$ to rewrite above  $\\mathbb{I}[h(\\vec{x})=1]P[Y=1|X=\\vec{x}]+\\mathbb{I}[h(\\vec{x})=0]P[Y=0|X=\\vec{x}] =\\mathbb{I}[h(\\vec{x})=1]\\eta(\\vec{x})+\\mathbb{I}[h(\\vec{x})=0](1- \\eta(\\vec{x}))$  Where $\\eta(\\vec{x}) := P[Y=1|X=\\vec{x}]$     Hence we need to show that $P[f(\\vec{x})=y|X=\\vec{x})]-P[g(\\vec{x})=y|X=\\vec{x})] \\geq 0$  This equals $\\eta(\\vec{x})[\\mathbb{I}[f(\\vec{x})=1]-\\mathbb{I}[g(\\vec{x})=1]]+(1-\\eta(\\vec{x}))[\\mathbb{I}[f(\\vec{x})=0]-\\mathbb{I}[g(\\vec{x})=0]] = (2\\eta(\\vec{x})-1)[\\mathbb{I}[f(\\vec{x})=1]-\\mathbb{I}[g(\\vec{x})=1]]$  You use $\\mathbb{I}[f(\\vec{x})=0] = 1 -\\mathbb{I}[f(\\vec{x})=1]$   If both classifiers guess the same output, there is no degradation in the performance in either classifier What happens if the outputs are different?  In either case$[\\mathbb{I}[f(\\vec{x})=1]-\\mathbb{I}[g(\\vec{x})=1]]=\\pm 1$ depending on if $f(x)$ is correct or $g(x)$ is correct, Say $f(x)$ returns 1:  This means that probability of $f(x)$ selecting 1 is greater than 0.5, hence $P[Y=1|X-\\vec{x}] =\\eta(\\vec{x}) \\geq 0.5$ so $(2\\eta(\\vec{x})-1)[\\mathbb{I}[f(\\vec{x})=1]-\\mathbb{I}[g(\\vec{x})=1]] \\geq 0$   A similar argument holds for $f(x)$ returning 0 (ie. the bayes classifier fails and the alternate classifier works)         Since we know that this works for a fixed example, we can integrate across all $x\\in X$ to prove the original theorem $P_{(\\vec{x},y)}[g(\\vec{x})=y] \\leq P_{(\\vec{x},y)}[f(\\vec{x})=y]$  Want to show $\\mathbb{E}[\\mathbb{I}[P_{(\\vec{x},y)}[g(\\vec{x})=y]]] - \\mathbb{E}[\\mathbb{I}[P_{(\\vec{x},y)}[f(\\vec{x})=y]]] \\geq 0$  $\\mathbb{E}[\\alpha(\\vec{x},y)] = \\int_{(\\vec({x},y)\\in X\\times Y)} \\alpha(\\vec{x},y)P((\\vec{x},y))d((\\vec{x},y))$ So we can rewrite the expectation values using linearity: $\\alpha(x,y)=\\mathbb{I}[P_{(\\vec{x},y)}[f(\\vec{x})=y]]$ and $\\beta(x,y)=\\mathbb{I}[P_{(\\vec{x},y)}[g(\\vec{x})=y]]$:  $\\mathbb{E}[\\mathbb{I}[P_{(\\vec{x},y)}[g(\\vec{x})=y]]] - \\mathbb{E}[\\mathbb{I}[P_{(\\vec{x},y)}[f(\\vec{x})=y]]] = \\int (\\alpha(\\vec{x},y)-\\beta(\\vec{x},y)) p(\\vec{x},y)d(x,y)=\\int_{x}[\\int_{y} (\\alpha-\\beta) p(y|x)dy]dx$  The inner integral is the probability we calculated earlier (the one that was always greater than zero). Hence the double integral is always greater than or equal to 0             Since we can’t normally acheive this classifier, how can we estimate it?  $f(\\vec{x})= argmax_{y\\in Y} P[Y=y|X=\\vec{x}]= argmax_{y\\in Y}\\frac{P[X=\\vec{x}|Y=y]\\cdot P[Y=y]}{P[X=\\vec{x}]}$  denominator independent of Y. This means that  $argmax_{y\\in Y}\\frac{P[X=\\vec{x}|Y=y]\\cdot P[Y=y]}{P[X=\\vec{x}]} = argmax_{y\\in Y}P[X=\\vec{x}|Y=y]\\cdot P[Y=y]$  The value of the function on the LHS is not the same as the RHS, but the y that maximizes the LHS and RHS is the same Instead of figuring out an infinite number of estimates (1 for each $\\vec{x}$ in $\\R^{d}$ space) you instead make 1 estimate for each $y\\in Y$, which is a much smaller space  Instead of an infinite number of Bernoulli distributions, you have a finite number of multidimensional distributions   $P[Y=y]$ is called the Class Prior or the prior $P[X=\\vec{x}|Y=y]$ is called the Class Conditional or the Conditional $P[Y=y|X=\\vec{x}]$ is called the Class Posterior or the Posterior          Maximum Likelihood Estimation  We are given some data $\\vec{x_{1}}… \\vec{x_{n}} \\in X$ independently draw Say we have a model class $P = \\{p_{\\theta}|\\theta\\in\\Theta\\}$ where $\\Theta$ is the parameter space  For Gaussians, $\\in \\Theta$ and $p_{\\theta} = \\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}exp(\\frac{-1}{2}\\frac{(x-\\mu)^{2}}{\\sigma^{2}})$   Find the model that best fits the data Define the likelihood function $\\mathbb{L}(\\theta|X)= P(X|\\theta)=P(x_{1},…,x_{n}|\\theta)=\\Pi_{i=1}^{n}P(\\vec{x_{i}}|\\theta) = \\Pi_{i=1}^{n}p_{\\theta}(\\vec{x_{i}})$  The likelihood function defines how probable (or how likely) is the data given the model $p_{\\theta}$   we want to find $\\theta$ that maximizes the likelihood function: $argmax_{\\theta\\in\\Theta}\\mathbb{L} = argmax_{\\theta\\in\\Theta}\\Pi_{i=1}^{n}p_{\\theta}(\\vec{x_{i}})$ Say for instance, that we have some data and we want to fit a Gaussian to it:  Find $argmax_{\\mu,\\sigma^{2}}\\Pi_{i=1}^{n}p_{\\mu,\\sigma^{2}}(\\vec{x_{i}})$ A trick to avoid using the product rule too much:  $argmax_{\\theta}\\mathbb{L}(\\theta|X)= argmax_{\\theta} log(\\mathbb{L}(\\theta|X))$ This turns the product into sums and eliminates the exp of the Guassian. After doing this manipulation, we get: find $argmax_{\\mu,\\sigma^{2}} \\Sigma_{i=1}^{n}[\\frac{-1}{2}log(2\\pi\\sigma^{2})-\\frac{(x_{i}-\\mu)^{2}}{2\\sigma^{2}}]$ Maximize w.r.t $\\mu$ to and solve for the stationary points yield $\\mu_{ML} = \\frac{1}{n}\\Sigma_{i=1}^{n}x_{i}$  This is an unbiased estimator that converges to the true $\\mu$ as the number of samples go to infinity   Can also take w.r.t. $\\sigma^{2}$: $\\sigma_{ML}^{2}=\\frac{1}{n}\\Sigma_{i=1}^{n}(x_{i}-\\mu)^{2}$  We can find the sample variance by plugging in $\\mu_{ML}$ for the true $\\mu$ (This is where the $\\frac{1}{n-1}$ thing comes from)        Example  Say that we want to estimate biological gender (male or female) based on weight and height The distribution is spread like $D[X\\times Y]$ The Bayes classifier is thus:  $f(\\vec{x}) = argmax_{y\\in\\{male,female\\}} P[X=\\vec{x}|Y=y]\\cdot P[Y=y]$  $\\hat{P}[Y=male]=$ fraction of training data labelled as male $\\hat{P}[Y=female]=$ fraction of training data labelled as female $\\hat{P}[X|Y=male]=p_{\\theta(male)}(X)$  Use MLE with only male data   $\\hat{P}[X|Y=female]=p_{\\theta(female)}(X)$  Use MLE with only female data   Say that the conditional follows a 2D Gaussian distribution     Another way to put this:  We have a bunch of labelled points in $\\mathbb{R^{2}}$  Look only at the male labels. Fit a 2D Gaussian to this data (Find some mean center and the covariance matrix) Do the same with the female labels     Once you have gotten your distributions, say that you get a new data point. The distribution (male or female) that yields the higher probability is your Bayes classifier’s output  Convergence  How fast does our sample converges to the population?  Define an error function $E = \\int(P(x)-\\hat{P}(x))^{2}dx \\leq n^{\\frac{-2}{2+d}} \\approx n^{\\frac{-1}{d}}$  If the dimensionality of the problem gets larger (d goes up), then the convergence becomes much slower (you need many many more samples in a higher dimensional space to get the same threshold as a lower dimensional space)  Say that you have a tolerance of $\\epsilon$ on the error. Then you need $n \\geq \\epsilon^{d}$ samples        Naive Bayes Classifier  $f(\\vec{x}) = argmax_{y\\in Y} P[X=\\vec{x}|Y=y]\\cdot p[Y=y] = argmax_{y\\in Y}\\Sigma_{y=1}^{d}P[X^{j}=x^{j}|Y=y]\\cdot P[Y=y]$  In words: each feature of the input (the $x_{i}$) are independent from each other given marginalization on the output You break a d-dimensional problem into d 1-dimensional problem, where each 1-d problem requires $\\frac{1}{\\sqrt{n}}$    How do you quantify the quality of a classifier?  If you know the population distribution, then just run the classifier with that data If you have a sample distribution, then you have a biased qualifier since you chose your classifying function from the training data Split the training data into training and testing data  The testing data provides an unbiased means of testing your model    Topic 2 Nearest K-Neighbor Importance of Closeness for k-Nearest Neighbors  If you have improper units (say that you measure human height in lightyears and human weight in micrograms), this can stretch and compress the axes and exaggerates the importance of a particular feature Choosing the correct closeness metric allows to to scale the axes to avoid this problem  Distances  If $X\\in \\R^{d}$, then an example of a distance metric is the $L^{p}$ norm ($(\\Sigma_{i=1}^{d} (\\vec{x_{i}}-\\vec{\\hat{x_{j}}})^{p})^\\frac{1}{p}$):  $p =2$ is Euclidean distance $p =1$ Manhattan distance or cityblock distance $p=\\infty$ max distance $p=0$ count ‘non-zero’ distance (ignore $\\frac{1}{p}$ power in norm definition)   Edit distance (genomics):  Domain specific: the number of mutations needed to convert one sequence to another   Kendell-Tau distance (to compare rankings)  What is the minimum number of adjacent pairwise swaps needed to convert 1 ranking to another?    Similarities  take the distance and construct the function $\\frac{1}{1+||\\vec{x_{1}}-\\vec{x_{2}}||_{p}}$ Cosine similarity: Find the cosine between the two vector  Topic 3 Topic 4 Topic 5 Topic 6 Topic 7 Topic 8 Topic 9 ",
  "wordCount" : "1792",
  "inLanguage": "en",
  "datePublished": "2023-01-17T22:19:16-05:00",
  "dateModified": "2023-02-01T20:49:38-05:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://mushetty.me/notes/machinelearning/machine/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "mushetty.me",
    "logo": {
      "@type": "ImageObject",
      "url": "https://mushetty.me/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://mushetty.me" accesskey="h" title="mushetty.me (Alt + H)">mushetty.me</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://mushetty.me/simulations/" title="Simulations">
                    <span>Simulations</span>
                </a>
            </li>
            <li>
                <a href="https://mushetty.me/notes/" title="Notes">
                    <span>Notes</span>
                </a>
            </li>
            <li>
                <a href="https://mushetty.me/posts/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      Machine Learning Notes
    </h1>
    <div class="post-meta"><span title='2023-01-17 22:19:16 -0500 EST'>Date Created: January 17, 2023</span>&nbsp;·&nbsp;<span title='2023-02-01 20:49:38 -0500 EST'>Last Modified: February 1, 2023</span>

</div>
  </header> 
  <div class="post-content"><p>Compilation of notes for Machine Learning class for Spring 2023.</p>
<ul>
<li><a href="#administrative-stuff">Administrative Stuff</a></li>
<li><a href="#topic-1">Topic 1</a>
<ul>
<li><a href="#workflow-of-classification-problems-supervised-learning">Workflow of Classification Problems (Supervised Learning)</a></li>
<li><a href="#statistical-approach">Statistical Approach</a>
<ul>
<li><a href="#classifier">Classifier</a></li>
</ul>
</li>
<li><a href="#maximum-likelihood-estimation">Maximum Likelihood Estimation</a>
<ul>
<li><a href="#example">Example</a></li>
</ul>
</li>
<li><a href="#convergence">Convergence</a></li>
<li><a href="#naive-bayes-classifier">Naive Bayes Classifier</a></li>
<li><a href="#how-do-you-quantify-the-quality-of-a-classifier">How do you quantify the quality of a classifier?</a></li>
</ul>
</li>
<li><a href="#topic-2">Topic 2</a>
<ul>
<li><a href="#nearest-k-neighbor">Nearest K-Neighbor</a>
<ul>
<li><a href="#importance-of-closeness-for-k-nearest-neighbors">Importance of Closeness for k-Nearest Neighbors</a>
<ul>
<li><a href="#distances">Distances</a></li>
<li><a href="#similarities">Similarities</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="#topic-3">Topic 3</a></li>
<li><a href="#topic-4">Topic 4</a></li>
<li><a href="#topic-5">Topic 5</a></li>
<li><a href="#topic-6">Topic 6</a></li>
<li><a href="#topic-7">Topic 7</a></li>
<li><a href="#topic-8">Topic 8</a></li>
<li><a href="#topic-9">Topic 9</a></li>
</ul>
<h2 id="administrative-stuff">Administrative Stuff<a hidden class="anchor" aria-hidden="true" href="#administrative-stuff">#</a></h2>
<ul>
<li>All homework is submitted via Gradescope.
<ul>
<li>Written parts must be PDFs and be typeset.
<ul>
<li>Plots and data analysis from programming part must be included in written part</li>
</ul>
</li>
<li>Programming parts are mostly turned in as a separate assignment on Gradescope</li>
</ul>
</li>
<li>40 % HW, 30% Midterm, 30% Final</li>
</ul>
<h2 id="topic-1">Topic 1<a hidden class="anchor" aria-hidden="true" href="#topic-1">#</a></h2>
<ul>
<li>Inputs encoded as vectors ($x \in X$):
<ul>
<li>$\vec{x} = &lt;x_{1},x_{2},&hellip;x_{n}&gt;$</li>
<li>Can think of each component as a measurement that you make</li>
</ul>
</li>
<li>Output is another vector ($y \in Y$):
<ul>
<li>$\vec{y} = &lt;y_{1},y_{2},&hellip;y_{m}&gt;$</li>
</ul>
</li>
<li>Goal is to figure out the function that maps x to y
<ul>
<li>You only have a limited number of samples from X
<ul>
<li>You need to make predictions from this limited sample size</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="workflow-of-classification-problems-supervised-learning">Workflow of Classification Problems (Supervised Learning)<a hidden class="anchor" aria-hidden="true" href="#workflow-of-classification-problems-supervised-learning">#</a></h3>
<ul>
<li>$(\vec{x_{1}},y_{1}),(\vec{x_{2}},y_{2})&hellip; \in X \times Y$
<ul>
<li>Example: $X = \mathbb{R^{d}}$ and $Y = {0,1}$ for a binary classification from a image with d pixels</li>
<li>Assumption: there exists a &ldquo;relatively simple&rdquo; function $f^{*}: X \rightarrow Y$ such that $f^{*}(\vec{x_{i}}) = y_{i}$ for most i
<ul>
<li>$*$ in ML implies some optimum value (in this case, an optimal function)</li>
<li><strong>Most</strong> includes that possibility that there is some fundamental noise in your data</li>
<li>Say someone wrote a number that kind of looks like 7 and kinda looks like 1. For the same image, the true $y_{i}$ could be either 7 or 1  (depending on the person&rsquo;s intentions). Hence, to force $f^{*}$ be a correct for all inputs misses this uncertainty in the true output</li>
</ul>
</li>
<li>Learning task: given $n$ examples from the data, from $\hat{f} \approx f^{*}$
<ul>
<li>$\hat{f}$ denotes a function that tries its best to be optimal</li>
</ul>
</li>
<li>Goal: $\hat{f}$ gives mostly correct prediction on unseen examples</li>
</ul>
</li>
</ul>
<h3 id="statistical-approach">Statistical Approach<a hidden class="anchor" aria-hidden="true" href="#statistical-approach">#</a></h3>
<ul>
<li>$(\vec{x_{1}},y_{1}),(\vec{x_{2}},y_{2})&hellip;(\vec{x_{n}},y_{n})$ samples are drawn from the underlying distribution
<ul>
<li>For simplicity, we assume each sample is drawn independently from the <strong>same</strong> underlying distribution is (called i.i.d. assumption)</li>
</ul>
</li>
<li>The learning algorithm draws $\hat{f}$ from a pool of models $\mathbb{F}$ that maximizes the label agreement with the training data
<ul>
<li>How do we select $f \in \mathbb{F}$?</li>
<li>Maximum likelihood (best fits the data)</li>
<li>Maximum a posteriori (best fits the data but incorporates prior assumptions)</li>
<li>Optimization of &lsquo;loss&rsquo; criterion (best discriminates the labels)</li>
</ul>
</li>
</ul>
<h4 id="classifier">Classifier<a hidden class="anchor" aria-hidden="true" href="#classifier">#</a></h4>
<ul>
<li>We are given a joint input/output space ($X \times Y$)
<ul>
<li>The data is distributed like $D(X \times Y)$
<ul>
<li>You have a region where your inputs can reside in ($X \times Y$) and D tells you the density of inputs on the space</li>
<li>You can visualize this space by either:
<ul>
<li>Taking slices at a fixed variable value ($P[Y,X=x]$) or the conditional distribution</li>
<li>Adding up all the slices along a variable ($P[Y]$) or the marginal distribution</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>A classifier is a measurable function of the type $f: x \in Y$
<ul>
<li>Ex1 (Constant): $f_{1}(\vec{x}) = y$ for some fixed $y \in Y$.</li>
<li>Ex2(Threshold): $f_{2}(x) = \begin{cases} 0\ if \ x \geq 5 \\ 1 \ otherwise  \end{cases}$</li>
<li>Ex3 (Majority class): $f_{3}(x) = arg\ max_{y\in Y} P[Y=y]$
<ul>
<li>This asks: What argument in Y yields the maximum probability?</li>
<li>Implicitly, this probability is the marginalized distribution on X</li>
<li>More explicitly, you can write probability as:</li>
<li>$P[Y=y] = P_{y \approx D}|_{Y}[Y=y]$
<ul>
<li>In words, you draw a (x,y) pair from D, and you only pay attention to the y part</li>
</ul>
</li>
</ul>
</li>
<li>None of these are particularly good/generally applicable classifiers</li>
<li>Ex4 (Sample Average Class):
<ul>
<li>$\frac{1}{n}\Sigma \mathbb{I}[f(x_{i}) = y_{i}]$
<ul>
<li>$\mathbb{I}$ is the indicator function that maps a boolean expression (like $f(x_{i}) = y_{i}$) to either 0 (false) or 1 (true)</li>
<li>This is from a sample</li>
</ul>
</li>
</ul>
</li>
<li>Ex5 (Population Average):
<ul>
<li>$\mathbb{E}_{(x,y)\in D}[\mathbb{I}[f(x)=y]]= P[f(x)=y]$
<ul>
<li>This is on the entire population. Essentially a probability that states how often this classifier f gets the output correct</li>
<li>called the <strong>accuracy function</strong> acc(f)</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Let&rsquo;s look at the following classifier:
<ul>
<li>$f(\vec{x})= arg\ max_{y\in Y}\ P[y=Y|X=\vec{x}]$
<ul>
<li>In words, find y that maximizes the probability given a particular x (called <strong>Bayes</strong> classifier)</li>
<li>This is the best classifier. But most of the time, you can&rsquo;t actually compute $P[y=Y|X=\vec{x}]$ for all inputs. You try your best to estimate these probabilities</li>
<li>Proof:
<ul>
<li>Assume binary classification for output space (for simplicity)
<ul>
<li>Let $f(\vec{x})= arg\ max_{y\in Y}\ P[y=Y|X=\vec{x}]$. Let $g(\vec{x})\rightarrow \{0,1\}$. Then $P_{(\vec{x},y)}[g(\vec{x})=y] \leq P_{(\vec{x},y)}[f(\vec{x})=y]$</li>
</ul>
</li>
<li>Let&rsquo;s look at a single example (Fix $\vec{x}\in X$). Then for any classifier h
<ul>
<li>$P[h(\vec{x})=y|X=\vec{x}]=P[h(\vec{x})=1|X=\vec{x}]+P[h(\vec{x})=0|X=\vec{x}]$</li>
<li>Since $h(\vec{x})=1$ is a constant, we can use $\mathbb{I}$ to rewrite above
<ul>
<li>$\mathbb{I}[h(\vec{x})=1]P[Y=1|X=\vec{x}]+\mathbb{I}[h(\vec{x})=0]P[Y=0|X=\vec{x}] =\mathbb{I}[h(\vec{x})=1]\eta(\vec{x})+\mathbb{I}[h(\vec{x})=0](1- \eta(\vec{x}))$
<ul>
<li>Where $\eta(\vec{x}) := P[Y=1|X=\vec{x}]$</li>
</ul>
</li>
</ul>
</li>
<li>Hence we need to show that $P[f(\vec{x})=y|X=\vec{x})]-P[g(\vec{x})=y|X=\vec{x})] \geq 0$
<ul>
<li>This equals $\eta(\vec{x})[\mathbb{I}[f(\vec{x})=1]-\mathbb{I}[g(\vec{x})=1]]+(1-\eta(\vec{x}))[\mathbb{I}[f(\vec{x})=0]-\mathbb{I}[g(\vec{x})=0]] = (2\eta(\vec{x})-1)[\mathbb{I}[f(\vec{x})=1]-\mathbb{I}[g(\vec{x})=1]]$
<ul>
<li>You use $\mathbb{I}[f(\vec{x})=0] = 1 -\mathbb{I}[f(\vec{x})=1]$</li>
</ul>
</li>
<li>If both classifiers guess the same output, there is no degradation in the performance in either classifier</li>
<li>What happens if the outputs are different?
<ul>
<li>In either case$[\mathbb{I}[f(\vec{x})=1]-\mathbb{I}[g(\vec{x})=1]]=\pm 1$ depending on if $f(x)$ is correct or $g(x)$ is correct,</li>
<li>Say $f(x)$ returns 1:
<ul>
<li>This means that probability of $f(x)$ selecting 1 is greater than 0.5, hence $P[Y=1|X-\vec{x}] =\eta(\vec{x}) \geq 0.5$ so $(2\eta(\vec{x})-1)[\mathbb{I}[f(\vec{x})=1]-\mathbb{I}[g(\vec{x})=1]] \geq 0$</li>
</ul>
</li>
<li>A similar argument holds for $f(x)$ returning 0 (ie. the bayes classifier fails and the alternate classifier works)</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Since we know that this works for a fixed example, we can integrate across all $x\in X$ to prove the original theorem $P_{(\vec{x},y)}[g(\vec{x})=y] \leq P_{(\vec{x},y)}[f(\vec{x})=y]$
<ul>
<li>Want to show $\mathbb{E}[\mathbb{I}[P_{(\vec{x},y)}[g(\vec{x})=y]]] - \mathbb{E}[\mathbb{I}[P_{(\vec{x},y)}[f(\vec{x})=y]]] \geq 0$
<ul>
<li>$\mathbb{E}[\alpha(\vec{x},y)] = \int_{(\vec({x},y)\in X\times Y)} \alpha(\vec{x},y)P((\vec{x},y))d((\vec{x},y))$</li>
<li>So we can rewrite the expectation values using linearity: $\alpha(x,y)=\mathbb{I}[P_{(\vec{x},y)}[f(\vec{x})=y]]$ and $\beta(x,y)=\mathbb{I}[P_{(\vec{x},y)}[g(\vec{x})=y]]$:
<ul>
<li>$\mathbb{E}[\mathbb{I}[P_{(\vec{x},y)}[g(\vec{x})=y]]] - \mathbb{E}[\mathbb{I}[P_{(\vec{x},y)}[f(\vec{x})=y]]] = \int (\alpha(\vec{x},y)-\beta(\vec{x},y)) p(\vec{x},y)d(x,y)=\int_{x}[\int_{y} (\alpha-\beta) p(y|x)dy]dx$
<ul>
<li>The inner integral is the probability we calculated earlier (the one that was always greater than zero). Hence the double integral is always greater than or equal to 0</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Since we can&rsquo;t normally acheive this classifier, how can we estimate it?
<ul>
<li>$f(\vec{x})= argmax_{y\in Y} P[Y=y|X=\vec{x}]= argmax_{y\in Y}\frac{P[X=\vec{x}|Y=y]\cdot P[Y=y]}{P[X=\vec{x}]}$
<ul>
<li>denominator independent of Y. This means that
<ul>
<li>$argmax_{y\in Y}\frac{P[X=\vec{x}|Y=y]\cdot P[Y=y]}{P[X=\vec{x}]} = argmax_{y\in Y}P[X=\vec{x}|Y=y]\cdot P[Y=y]$
<ul>
<li>The value of the function on the LHS is not the same as the RHS, but the y that maximizes the LHS and RHS is the same</li>
<li>Instead of figuring out an infinite number of estimates (1 for each $\vec{x}$ in $\R^{d}$ space) you instead make 1 estimate for each $y\in Y$, which is a much smaller space
<ul>
<li>Instead of an infinite number of Bernoulli distributions, you have a finite number of multidimensional distributions</li>
</ul>
</li>
<li>$P[Y=y]$ is called the <strong>Class Prior</strong> or the <strong>prior</strong></li>
<li>$P[X=\vec{x}|Y=y]$ is called the <strong>Class Conditional</strong> or the <strong>Conditional</strong></li>
<li>$P[Y=y|X=\vec{x}]$ is called the <strong>Class Posterior</strong> or the <strong>Posterior</strong></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="maximum-likelihood-estimation">Maximum Likelihood Estimation<a hidden class="anchor" aria-hidden="true" href="#maximum-likelihood-estimation">#</a></h3>
<ul>
<li>We are given some data $\vec{x_{1}}&hellip; \vec{x_{n}} \in X$ independently draw</li>
<li>Say we have a model class $P = \{p_{\theta}|\theta\in\Theta\}$ where $\Theta$ is the parameter space
<ul>
<li>For Gaussians, $&lt;\mu,\sigma&gt;\in \Theta$ and $p_{\theta} = \frac{1}{\sqrt{2\pi\sigma^{2}}}exp(\frac{-1}{2}\frac{(x-\mu)^{2}}{\sigma^{2}})$</li>
</ul>
</li>
<li>Find the model that best fits the data</li>
<li>Define the likelihood function $\mathbb{L}(\theta|X)= P(X|\theta)=P(x_{1},&hellip;,x_{n}|\theta)=\Pi_{i=1}^{n}P(\vec{x_{i}}|\theta) = \Pi_{i=1}^{n}p_{\theta}(\vec{x_{i}})$
<ul>
<li>The likelihood function defines how <strong>probable</strong> (or how likely) is the data given the model $p_{\theta}$</li>
</ul>
</li>
<li>we want to find $\theta$ that maximizes the likelihood function: $argmax_{\theta\in\Theta}\mathbb{L} = argmax_{\theta\in\Theta}\Pi_{i=1}^{n}p_{\theta}(\vec{x_{i}})$</li>
<li>Say for instance, that we have some data and we want to fit a Gaussian to it:
<ul>
<li>Find $argmax_{\mu,\sigma^{2}}\Pi_{i=1}^{n}p_{\mu,\sigma^{2}}(\vec{x_{i}})$</li>
<li>A trick to avoid using the product rule too much:
<ul>
<li>$argmax_{\theta}\mathbb{L}(\theta|X)= argmax_{\theta} log(\mathbb{L}(\theta|X))$</li>
<li>This turns the product into sums and eliminates the exp of the Guassian. After doing this manipulation, we get:</li>
<li>find $argmax_{\mu,\sigma^{2}} \Sigma_{i=1}^{n}[\frac{-1}{2}log(2\pi\sigma^{2})-\frac{(x_{i}-\mu)^{2}}{2\sigma^{2}}]$</li>
<li>Maximize w.r.t $\mu$ to and solve for the stationary points yield $\mu_{ML} = \frac{1}{n}\Sigma_{i=1}^{n}x_{i}$
<ul>
<li>This is an unbiased estimator that converges to the true $\mu$ as the number of samples go to infinity</li>
</ul>
</li>
<li>Can also take w.r.t. $\sigma^{2}$: $\sigma_{ML}^{2}=\frac{1}{n}\Sigma_{i=1}^{n}(x_{i}-\mu)^{2}$
<ul>
<li>We can find the sample variance by plugging in $\mu_{ML}$ for the true $\mu$ (This is where the $\frac{1}{n-1}$ thing comes from)</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="example">Example<a hidden class="anchor" aria-hidden="true" href="#example">#</a></h4>
<ul>
<li>Say that we want to estimate biological gender (male or female) based on weight and height</li>
<li>The distribution is spread like $D[X\times Y]$</li>
<li>The Bayes classifier is thus:
<ul>
<li>$f(\vec{x}) = argmax_{y\in\{male,female\}} P[X=\vec{x}|Y=y]\cdot P[Y=y]$
<ul>
<li>$\hat{P}[Y=male]=$ fraction of training data labelled as male</li>
<li>$\hat{P}[Y=female]=$ fraction of training data labelled as female</li>
<li>$\hat{P}[X|Y=male]=p_{\theta(male)}(X)$
<ul>
<li>Use MLE with only male data</li>
</ul>
</li>
<li>$\hat{P}[X|Y=female]=p_{\theta(female)}(X)$
<ul>
<li>Use MLE with only female data</li>
</ul>
</li>
<li>Say that the conditional follows a 2D Gaussian distribution</li>
</ul>
</li>
</ul>
</li>
<li>Another way to put this:
<ul>
<li>We have a bunch of labelled points in $\mathbb{R^{2}}$
<ul>
<li>Look only at the male labels. Fit a 2D Gaussian to this data (Find some mean center and the covariance matrix)</li>
<li>Do the same with the female labels</li>
</ul>
</li>
</ul>
</li>
<li>Once you have gotten your distributions, say that you get a new data point. The distribution (male or female) that yields the higher probability is your Bayes classifier&rsquo;s output</li>
</ul>
<h3 id="convergence">Convergence<a hidden class="anchor" aria-hidden="true" href="#convergence">#</a></h3>
<ul>
<li>How fast does our sample converges to the population?
<ul>
<li>Define an error function $E = \int(P(x)-\hat{P}(x))^{2}dx \leq n^{\frac{-2}{2+d}} \approx n^{\frac{-1}{d}}$
<ul>
<li>If the dimensionality of the problem gets larger (d goes up), then the convergence becomes much slower (you need many many more samples in a higher dimensional space to get the same threshold as a lower dimensional space)
<ul>
<li>Say that you have a tolerance of $\epsilon$ on the error. Then you need $n \geq \epsilon^{d}$ samples</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="naive-bayes-classifier">Naive Bayes Classifier<a hidden class="anchor" aria-hidden="true" href="#naive-bayes-classifier">#</a></h3>
<ul>
<li>$f(\vec{x}) = argmax_{y\in Y} P[X=\vec{x}|Y=y]\cdot p[Y=y] = argmax_{y\in Y}\Sigma_{y=1}^{d}P[X^{j}=x^{j}|Y=y]\cdot P[Y=y]$
<ul>
<li>In words: each feature of the input (the $x_{i}$) are independent from each other given marginalization on the output</li>
<li>You break a d-dimensional problem into d 1-dimensional problem, where each 1-d problem requires $\frac{1}{\sqrt{n}}$</li>
</ul>
</li>
</ul>
<h3 id="how-do-you-quantify-the-quality-of-a-classifier">How do you quantify the quality of a classifier?<a hidden class="anchor" aria-hidden="true" href="#how-do-you-quantify-the-quality-of-a-classifier">#</a></h3>
<ul>
<li>If you know the population distribution, then just run the classifier with that data</li>
<li>If you have a sample distribution, then you have a biased qualifier since you chose your classifying function from the training data</li>
<li>Split the training data into training and testing data
<ul>
<li>The testing data provides an unbiased means of testing your model</li>
</ul>
</li>
</ul>
<h2 id="topic-2">Topic 2<a hidden class="anchor" aria-hidden="true" href="#topic-2">#</a></h2>
<h3 id="nearest-k-neighbor">Nearest K-Neighbor<a hidden class="anchor" aria-hidden="true" href="#nearest-k-neighbor">#</a></h3>
<h4 id="importance-of-closeness-for-k-nearest-neighbors">Importance of Closeness for k-Nearest Neighbors<a hidden class="anchor" aria-hidden="true" href="#importance-of-closeness-for-k-nearest-neighbors">#</a></h4>
<ul>
<li>If you have improper units (say that you measure human height in lightyears and human weight in micrograms), this can stretch and compress the axes and exaggerates the importance of a particular feature</li>
<li>Choosing the correct closeness metric allows to to scale the axes to avoid this problem</li>
</ul>
<h5 id="distances">Distances<a hidden class="anchor" aria-hidden="true" href="#distances">#</a></h5>
<ul>
<li>If $X\in \R^{d}$, then an example of a distance metric is the $L^{p}$ norm ($(\Sigma_{i=1}^{d} (\vec{x_{i}}-\vec{\hat{x_{j}}})^{p})^\frac{1}{p}$):
<ul>
<li>$p =2$ is Euclidean distance</li>
<li>$p =1$ Manhattan distance or cityblock distance</li>
<li>$p=\infty$ max distance</li>
<li>$p=0$ count &lsquo;non-zero&rsquo; distance (ignore $\frac{1}{p}$ power in norm definition)</li>
</ul>
</li>
<li>Edit distance (genomics):
<ul>
<li>Domain specific: the number of mutations needed to convert one sequence to another</li>
</ul>
</li>
<li>Kendell-Tau distance (to compare rankings)
<ul>
<li>What is the minimum number of adjacent pairwise swaps needed to convert 1 ranking to another?</li>
</ul>
</li>
</ul>
<h5 id="similarities">Similarities<a hidden class="anchor" aria-hidden="true" href="#similarities">#</a></h5>
<ul>
<li>take the distance and construct the function $\frac{1}{1+||\vec{x_{1}}-\vec{x_{2}}||_{p}}$</li>
<li>Cosine similarity: Find the cosine between the two vector</li>
</ul>
<h2 id="topic-3">Topic 3<a hidden class="anchor" aria-hidden="true" href="#topic-3">#</a></h2>
<h2 id="topic-4">Topic 4<a hidden class="anchor" aria-hidden="true" href="#topic-4">#</a></h2>
<h2 id="topic-5">Topic 5<a hidden class="anchor" aria-hidden="true" href="#topic-5">#</a></h2>
<h2 id="topic-6">Topic 6<a hidden class="anchor" aria-hidden="true" href="#topic-6">#</a></h2>
<h2 id="topic-7">Topic 7<a hidden class="anchor" aria-hidden="true" href="#topic-7">#</a></h2>
<h2 id="topic-8">Topic 8<a hidden class="anchor" aria-hidden="true" href="#topic-8">#</a></h2>
<h2 id="topic-9">Topic 9<a hidden class="anchor" aria-hidden="true" href="#topic-9">#</a></h2>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2023 <a href="https://mushetty.me">mushetty.me</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
