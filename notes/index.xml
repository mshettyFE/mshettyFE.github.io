<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>mushetty.me</title>
    <link>https://mushetty.me/notes/</link>
    <description>Recent content on mushetty.me</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://mushetty.me/notes/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Mechanics: Fundamentals and Applications</title>
      <link>https://mushetty.me/notes/mechanics/mech/</link>
      <pubDate>Tue, 17 Jan 2023 22:19:47 -0500</pubDate>
      
      <guid>https://mushetty.me/notes/mechanics/mech/</guid>
      <description>Compilation of notes for Mechanics class for Spring 2023.
 Administrative Stuff Lecture 1 Lecture 2 Lecture 3: Lecture 4  Quality Factor Example 1 Example 2   Lecture 5  Example 1: Phase Path   Lecture 6  Chaos in Pendulum  Weakly Driven Strongly Driven   Poincare Sections   Lecture 7  Administrative Stuff  Book: No purchase necessary. Problems handed out. Will be randomly called to solve HW problems HW not counted towards final grade Two closed book quizzes (25% each)  One around March 1 One around April 17   One final exam (50%)  Lecture 1   HW Problems due before class on Jan 23</description>
    </item>
    
    <item>
      <title>Machine Learning Notes</title>
      <link>https://mushetty.me/notes/machinelearning/machine/</link>
      <pubDate>Tue, 17 Jan 2023 22:19:16 -0500</pubDate>
      
      <guid>https://mushetty.me/notes/machinelearning/machine/</guid>
      <description>Compilation of notes for Machine Learning class for Spring 2023.
 Administrative Stuff Topic 1  Workflow of Classification Problems (Supervised Learning) Statistical Approach  Classifier   Maximum Likelihood Estimation  Example   Convergence Naive Bayes Classifier How do you quantify the quality of a classifier? Approaches to Classification  Generative Approach  Advantages Disadvantages   Discriminative Approach  Advantages Disadvantages       Topic 2  Nearest K-Neighbor  Importance of Closeness for k-Nearest Neighbors  Distances Similarities   Issues with the nearest neighbor k-NN Optimality  Proof Practical Considerations of k-nearest neighbor  Finding the k-th nearest neighbors takes time   Metric of Closeness is Sometimes Unclear  Derivative w.</description>
    </item>
    
    <item>
      <title>ML Refresher Notes</title>
      <link>https://mushetty.me/notes/mlnotes/ml_notes/</link>
      <pubDate>Sat, 07 Jan 2023 17:29:54 -0500</pubDate>
      
      <guid>https://mushetty.me/notes/mlnotes/ml_notes/</guid>
      <description>Here is a compendium of my notes that I took to review for Machine Learning. This was meant to be a quick refresher on concepts and to put everything in one place. For a less cursory version, see the background section under Resources at the course website.
 Probability and Statistics  Basic Concepts  Axioms of Probability Definitions Baye&amp;rsquo;s Rule Expectation   Common Probability Distributions  Bernoulli Distribution Binomial Distribution Poisson Distribution Categorical Distribution Multinomial Distribution Guassian(Normal) Distribution Multivariate Gaussian Distribution Laplace distribution Dirac Delta Distribution Mixtures of Distributions   Common Functions  Logistic sigmoid $\sigma(x)$ Softplus Function $\Zeta(x)$   Information Theory  Self-Information Shannon Entropy Kullback-Leibler (KL) divergence Cross-entropy Exponential Distribution   Chi-squared Distribution  Basics Goodness of Fit (GOF) Independence   T-test  One Sample Two Sample  Paired Unpaired       Linear Algebra  Types of Objects in Linear Algebra Matrix Operations Central Problem of Linear Algebra  Gaussian Elimination Reduced Row Echelon Form (RREF)  Reading of Solutions of Ax=b from RREF     LU Decomposition  LDU Decomposition   Identity and Inverses Vector Spaces  Subspaces  Orthogonal Complements     Linear Transformations  Diagonalization  Change of Basis     Linear Dependence and Span Basis and Dimension Norms Orthogonal Bases Gram-Schmidt and Orthogonal Complements Eigendecomposition Singular Value Decomposition (SVD) Moore-Penrose Pseudoinverse QR Decomposition  Gram-Schmidt   Trace Determinant Kernel, Range, Nullity,Rank  Mapping definitions Kernel Rank and Nullity   Least Squares    Probability and Statistics Basic Concepts Axioms of Probability  Probability Measure $P: \mathbb{F} \rightarrow \mathbb{{R}}$ such that  $P(A) \geq 0$ for all $A \in \mathbb{F}$ $P(\Omega) = 1$ If $A_{1},A_{2}&amp;hellip;$ are disjoint events, then  $P(\cup A_{i}) = \Sigma_{i} P(A_{i})$      Definitions  Sample space $\Omega$: The set of all possible outcomes Event space $\mathbb{F}:A$ is a subset of $\Omega$ a random variable quantity that has an uncertain value.</description>
    </item>
    
  </channel>
</rss>
